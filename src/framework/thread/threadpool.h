// Copyright Querysoft Limited 2008 - 2025
//
// Permission is hereby granted, free of charge, to any person or organization
// obtaining a copy of the software and accompanying documentation covered by
// this license (the "Software") to use, reproduce, display, distribute,
// execute, and transmit the Software, and to prepare derivative works of the
// Software, and to permit third-parties to whom the Software is furnished to
// do so, all subject to the following:
// 
// The copyright notices in the Software and this entire statement, including
// the above license grant, this restriction and the following disclaimer,
// must be included in all copies of the Software, in whole or in part, and
// all derivative works of the Software, unless such copies or derivative
// works are solely in the form of machine-executable object code generated by
// a source language processor.
// 
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
// SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
// FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
// DEALINGS IN THE SOFTWARE.

#ifndef QOR_PP_H_FRAMEWORK_THREADPOOL
#define QOR_PP_H_FRAMEWORK_THREADPOOL
 
#include <algorithm>
#include <chrono>
#include <condition_variable>
#include <coroutine>
#include <cstddef>
#include <cstdint>
#include <functional>
#include <future>
#include <iostream>
#include <limits>
#include <memory>
#include <mutex>
#include <optional>
#include <queue>
#include <string>
#include <thread>
#include <tuple>
#include <type_traits>
#include <utility>
#include <variant>
#include <vector>
#ifdef __cpp_concepts
    #include <concepts>
#endif
#ifdef __cpp_exceptions
    #include <exception>
    #include <stdexcept>
#endif
#ifdef __cpp_impl_three_way_comparison
    #include <compare>
#endif
#ifdef __cpp_lib_int_pow2
    #include <bit>
#endif
#ifdef __cpp_lib_semaphore
    #include <semaphore>
#endif
#include <stop_token>
#include "pool/types.h"
#include "pool/pr_task.h"
#include "pool/concepts.h"
#include "pool/multifuture.h"
#include "pool/blocks.h"
#include "currentthread.h"
#include "pool/common_index_type.h"
#include "src/framework/role/ifeature.h"

namespace qor { namespace framework{

    struct qor_pp_module_interface(QOR_THREAD) wait_deadlock : public std::runtime_error
    {
        wait_deadlock() : std::runtime_error("wait_deadlock") {};
    };

    class qor_pp_module_interface(QOR_THREAD) ThreadPool : public IFeature
    {
    public:
        
        bool wait_deadlock_checks_enabled = true;                                                       //A flag indicating whether wait deadlock checks are enabled.

        ThreadPool()                                                                                    //Construct a new thread pool. The number of threads will be derived from total number of hardware threads available, as reported by the implementation. This is usually determined by the number of cores in the CPU. If a core is hyperthreaded, it will count as two threads.
        {
            SetThreadCount(0);
            SetInitFunction([] {});
        }

        explicit ThreadPool(const std::size_t num_threads)                                              //Construct a new thread pool with the specified number of threads.
        {
            SetThreadCount(num_threads);
            SetInitFunction([] {});
        }
        
        template <qor_pp_threadpool_init_func_concept(F)>                                               //Construct a new thread pool with the specified initialization function.
        explicit ThreadPool(F&& init)
        {
            SetThreadCount(0);
            SetInitFunction(std::forward<F>(init));
        }

        template <qor_pp_threadpool_init_func_concept(F)>                                               // Construct a new thread pool with the specified number of threads and initialization function.
        ThreadPool(const std::size_t num_threads, F&& init)
        {
            SetInitFunction(std::forward<F>(init));
            SetThreadCount(num_threads);
        }

        virtual void Setup();
        virtual void Shutdown();
        virtual ~ThreadPool() noexcept ;                                                                //Destruct the thread pool. Waits for all tasks to complete, then destroys all threads. If a cleanup function was set, it will run in each thread right before it is destroyed. Note that if the pool is paused, then any tasks still in the queue will never be executed.


        //Parallelize a loop by automatically splitting it into blocks and submitting each block separately to the queue, with the specified priority. The block function takes two arguments, the start and end of the block, so that it is only called once per block, but it is up to the user make sure the block function correctly deals with all the indices in each block. Does not return a `MultiFuture`, so the user must use `wait()` or some other method to ensure that the loop finishes executing, otherwise bad things will happen.
        //T1 The type of the first index. Should be a signed or unsigned integer.
        //T2 The type of the index after the last index. Should be a signed or unsigned integer.
        //F The type of the function to loop through.
        //first_index The first index in the loop.
        //index_after_last The index after the last index in the loop. The loop will iterate from `first_index` to `(index_after_last - 1)` inclusive. In other words, it will be equivalent to `for (T i = first_index; i < index_after_last; ++i)`. Note that if `index_after_last <= first_index`, no blocks will be submitted.
        //block A function that will be called once per block. Should take exactly two arguments: the first index in the block and the index after the last index in the block. `block(start, end)` should typically involve a loop of the form `for (T i = start; i < end; ++i)`.
        //num_blocks The maximum number of blocks to split the loop into. The default is 0, which means the number of blocks will be equal to the number of threads in the pool.
        //priority The priority of the tasks. Should be between -128 and +127 (a signed 8-bit integer). The default is 0. 
        template <typename T1, typename T2, typename T = common_index_type_t<T1, T2>, typename F>
        void PostBlocks(const T1 first_index, const T2 index_after_last, F&& block, const std::size_t num_blocks = 0, const priority_t priority = 0)
        {
            if (static_cast<T>(index_after_last) > static_cast<T>(first_index))
            {
                const std::shared_ptr<std::decay_t<F>> block_ptr = std::make_shared<std::decay_t<F>>(std::forward<F>(block));
                const Blocks blks(static_cast<T>(first_index), static_cast<T>(index_after_last), num_blocks ? num_blocks : thread_count);
                for (std::size_t blk = 0; blk < blks.get_num_blocks(); ++blk)
                {
                    PostTask(
                        [block_ptr, start = blks.start(blk), end = blks.end(blk)]
                        {
                            (*block_ptr)(start, end);
                        },
                        priority);
                }
            }
        }

        // Parallelize a loop by automatically splitting it into blocks and submitting each block separately to the queue, with the specified priority. The loop function takes one argument, the loop index, so that it is called many times per block. Does not return a `MultiFuture`, so the user must use `wait()` or some other method to ensure that the loop finishes executing, otherwise bad things will happen.
        // T1 The type of the first index. Should be a signed or unsigned integer.
        // T2 The type of the index after the last index. Should be a signed or unsigned integer.
        // F The type of the function to loop through.
        // first_index The first index in the loop.
        // index_after_last The index after the last index in the loop. The loop will iterate from `first_index` to `(index_after_last - 1)` inclusive. In other words, it will be equivalent to `for (T i = first_index; i < index_after_last; ++i)`. Note that if `index_after_last <= first_index`, no blocks will be submitted.
        // loop The function to loop through. Will be called once per index, many times per block. Should take exactly one argument: the loop index.
        // num_blocks The maximum number of blocks to split the loop into. The default is 0, which means the number of blocks will be equal to the number of threads in the pool.
        // priority The priority of the tasks. Should be between -128 and +127 (a signed 8-bit integer). The default is 0. 
        template <typename T1, typename T2, typename T = common_index_type_t<T1, T2>, typename F>
        void PostLoop(const T1 first_index, const T2 index_after_last, F&& loop, const std::size_t num_blocks = 0, const priority_t priority = 0)
        {
            if (static_cast<T>(index_after_last) > static_cast<T>(first_index))
            {
                const std::shared_ptr<std::decay_t<F>> loop_ptr = std::make_shared<std::decay_t<F>>(std::forward<F>(loop));
                const Blocks blks(static_cast<T>(first_index), static_cast<T>(index_after_last), num_blocks ? num_blocks : thread_count);
                for (std::size_t blk = 0; blk < blks.get_num_blocks(); ++blk)
                {
                    PostTask(
                        [loop_ptr, start = blks.start(blk), end = blks.end(blk)]
                        {
                            for (T i = start; i < end; ++i)
                                (*loop_ptr)(i);
                        },
                        priority);
                }
            }
        }

        //Submit a sequence of tasks enumerated by indices to the queue, with the specified priority. The sequence function takes one argument, the task index, and will be called once per index. Does not return a `MultiFuture`, so the user must use `wait()` or some other method to ensure that the sequence finishes executing, otherwise bad things will happen.
        // T1 The type of the first index. Should be a signed or unsigned integer.
        // T2 The type of the index after the last index. Should be a signed or unsigned integer.
        // F The type of the function used to define the sequence.
        // first_index The first index in the sequence.
        // index_after_last The index after the last index in the sequence. The sequence will iterate from `first_index` to `(index_after_last - 1)` inclusive. In other words, it will be equivalent to `for (T i = first_index; i < index_after_last; ++i)`. Note that if `index_after_last <= first_index`, no tasks will be submitted.
        // sequence The function used to define the sequence. Will be called once per index. Should take exactly one argument, the index.
        // priority The priority of the tasks. Should be between -128 and +127 (a signed 8-bit integer). The default is 0. 
        template <typename T1, typename T2, typename T = common_index_type_t<T1, T2>, typename F>
        void PostSequence(const T1 first_index, const T2 index_after_last, F&& sequence, const priority_t priority = 0)
        {
            if (static_cast<T>(index_after_last) > static_cast<T>(first_index))
            {
                const std::shared_ptr<std::decay_t<F>> sequence_ptr = std::make_shared<std::decay_t<F>>(std::forward<F>(sequence));
                for (T i = static_cast<T>(first_index); i < static_cast<T>(index_after_last); ++i)
                {
                    PostTask(
                        [sequence_ptr, i]
                        {
                            (*sequence_ptr)(i);
                        },
                        priority);
                }
            }
        }

        //Submit a function with no arguments and no return value into the task queue, with the specified priority. To submit a function with arguments, enclose it in a lambda expression. Does not return a future, so the user must use `wait()` or some other method to ensure that the task finishes executing, otherwise bad things will happen.
        // F The type of the function.
        // task The function to submit.
        // priority The priority of the task. Should be between -128 and +127 (a signed 8-bit integer). 
        template <typename F>
        void PostTask(F&& task, const priority_t priority = 0)
        {
            {
                const std::scoped_lock tasks_lock(tasks_mutex);
                tasks.emplace(std::forward<F>(task), priority);
            }
            task_available_cv.notify_one();
        }

        //Get a vector containing the underlying implementation-defined thread handles for each of the pool's threads, as obtained by `std::thread::native_handle()` (or `std::jthread::native_handle()` in C++20 and later).
        //return The native thread handles.     
        [[nodiscard]] std::vector<thread_t::native_handle_type> GetNativeHandles() const
        {
            std::vector<thread_t::native_handle_type> native_handles(thread_count);
            for (std::size_t i = 0; i < thread_count; ++i)
                native_handles[i] = threads[i].stdThread().native_handle();
            return native_handles;
        }

        [[nodiscard]] std::size_t GetCountOfTasksQueued() const
        {
            const std::scoped_lock tasks_lock(tasks_mutex);
            return tasks.size();
        }

        //Get the number of tasks currently being executed by the threads.
        [[nodiscard]] std::size_t GetCountOfTasksRunning() const
        {
            const std::scoped_lock tasks_lock(tasks_mutex);
            return tasks_running;
        }

        //Get the total number of unfinished tasks: either still waiting in the queue, or running in a thread. Note that `GetTotalCountOfTasks() == GetCountOfTasksQueued() + GetCountOfTasksRunning()`.
        //return The total number of tasks.
        [[nodiscard]] std::size_t GetTotalCountOfTasks() const
        {
            const std::scoped_lock tasks_lock(tasks_mutex);
            return tasks_running + tasks.size();
        }

        std::size_t GetThreadCount() const noexcept;

        //Get a vector containing the unique identifiers for each of the pool's threads, as obtained by `std::thread::get_id()` (or `std::jthread::get_id()` in C++20 and later).
        //return The unique thread identifiers.
        [[nodiscard]] std::vector<thread_t::id> GetThreadIds() const
        {
            std::vector<thread_t::id> thread_ids(thread_count);
            for (std::size_t i = 0; i < thread_count; ++i)
            {
                thread_ids[i] = threads[i].stdThread().get_id();
            }
            return thread_ids;
        }

        [[nodiscard]] bool IsPaused() const
        {
            const std::scoped_lock tasks_lock(tasks_mutex);
            return paused;
        }

        //Pause the pool. The workers will temporarily stop retrieving new tasks out of the queue, although any tasks already executed will keep running until they are finished. Only enabled if the flag `BS:tp::pause` is enabled in the template parameter.        
        void Pause()
        {
            const std::scoped_lock tasks_lock(tasks_mutex);
            paused = true;
        }

        // Purge all the tasks waiting in the queue. Tasks that are currently running will not be affected, but any tasks still waiting in the queue will be discarded, and will never be executed by the threads. Please note that there is no way to restore the purged tasks.
        void Purge()
        {
            const std::scoped_lock tasks_lock(tasks_mutex);
            tasks = {};
        }

        //Reset the pool with the total number of hardware threads available, as reported by the implementation. Waits for all currently running tasks to be completed, then destroys all threads in the pool and creates a new thread pool with the new number of threads. Any tasks that were waiting in the queue before the pool was reset will then be executed by the new threads. If the pool was paused before resetting it, the new pool will be paused as well.
        void Reset()
        {
            Reset(0, [](std::size_t) {});
        }

        //Reset the pool with a new number of threads. Waits for all currently running tasks to be completed, then destroys all threads in the pool and creates a new thread pool with the new number of threads. Any tasks that were waiting in the queue before the pool was reset will then be executed by the new threads. If the pool was paused before resetting it, the new pool will be paused as well.
        // num_threads The number of threads to use.
        void Reset(const std::size_t num_threads)
        {
            Reset(num_threads, [](std::size_t) {});
        }

        //Reset the pool with the total number of hardware threads available, as reported by the implementation, and a new initialization function. Waits for all currently running tasks to be completed, then destroys all threads in the pool and creates a new thread pool with the new number of threads and initialization function. Any tasks that were waiting in the queue before the pool was reset will then be executed by the new threads. If the pool was paused before resetting it, the new pool will be paused as well.
        // init An initialization function to run in each thread before it starts executing any submitted tasks. The function must have no return value, and can either take one argument, the thread index of type `std::size_t`, or zero arguments. It will be executed exactly once per thread, when the thread is first constructed. The initialization function must not throw any exceptions, as that will result in program termination. Any exceptions must be handled explicitly within the function.
        template <qor_pp_threadpool_init_func_concept(F)>
        void Reset(F&& init)
        {
            Reset(0, std::forward<F>(init));
        }

        // Reset the pool with a new number of threads and a new initialization function. Waits for all currently running tasks to be completed, then destroys all threads in the pool and creates a new thread pool with the new number of threads and initialization function. Any tasks that were waiting in the queue before the pool was reset will then be executed by the new threads. If the pool was paused before resetting it, the new pool will be paused as well.
        // num_threads The number of threads to use.
        // init An initialization function to run in each thread before it starts executing any submitted tasks. The function must have no return value, and can either take one argument, the thread index of type `std::size_t`, or zero arguments. It will be executed exactly once per thread, when the thread is first constructed. The initialization function must not throw any exceptions, as that will result in program termination. Any exceptions must be handled explicitly within the function.
        template <qor_pp_threadpool_init_func_concept(F)>
        void Reset(const std::size_t num_threads, F&& init)
        {
            std::unique_lock tasks_lock(tasks_mutex);
            const bool was_paused = paused;
            paused = true;
            tasks_lock.unlock();
            ResetPool(num_threads, std::forward<F>(init));
            tasks_lock.lock();
            paused = was_paused;
        }

        // Set the thread pool's cleanup function.
        // cleanup A cleanup function to run in each thread right before it is destroyed, which will happen when the pool is destructed or reset. The function must have no return value, and can either take one argument, the thread index of type `std::size_t`, or zero arguments. The cleanup function must not throw any exceptions, as that will result in program termination. Any exceptions must be handled explicitly within the function.
        template <qor_pp_threadpool_init_func_concept(F)>
        void SetCleanupFunction(F&& cleanup)
        {
            if constexpr (std::is_invocable_v<F, std::size_t>)
            {
                cleanup_func = std::forward<F>(cleanup);
            }
            else
            {
                cleanup_func = [cleanup = std::forward<F>(cleanup)](std::size_t)
                {
                    cleanup();
                };
            }
        }

        // Parallelize a loop by automatically splitting it into blocks and submitting each block separately to the queue, with the specified priority. The block function takes two arguments, the start and end of the block, so that it is only called once per block, but it is up to the user make sure the block function correctly deals with all the indices in each block. Returns a `MultiFuture` that contains the futures for all of the blocks.
        // T1 The type of the first index. Should be a signed or unsigned integer.
        // T2 The type of the index after the last index. Should be a signed or unsigned integer.
        // F The type of the function to loop through.
        // R The return type of the function to loop through (can be `void`).
        // first_index The first index in the loop.
        // index_after_last The index after the last index in the loop. The loop will iterate from `first_index` to `(index_after_last - 1)` inclusive. In other words, it will be equivalent to `for (T i = first_index; i < index_after_last; ++i)`. Note that if `index_after_last <= first_index`, no blocks will be submitted, and an empty `MultiFuture` will be returned.
        // block A function that will be called once per block. Should take exactly two arguments: the first index in the block and the index after the last index in the block. `block(start, end)` should typically involve a loop of the form `for (T i = start; i < end; ++i)`.
        // num_blocks The maximum number of blocks to split the loop into. The default is 0, which means the number of blocks will be equal to the number of threads in the pool.
        // priority The priority of the tasks. Should be between -128 and +127 (a signed 8-bit integer). The default is 0. Only taken into account if the flag `tp::priority` is enabled in the template parameter, otherwise has no effect.
        // A `MultiFuture` that can be used to wait for all the blocks to finish. If the block function returns a value, the `MultiFuture` can also be used to obtain the values returned by each block.
        template <typename T1, typename T2, typename T = common_index_type_t<T1, T2>, typename F, typename R = std::invoke_result_t<std::decay_t<F>, T, T>>
        [[nodiscard]] MultiFuture<R> SubmitBlocks(const T1 first_index, const T2 index_after_last, F&& block, const std::size_t num_blocks = 0, const priority_t priority = 0)
        {
            if (static_cast<T>(index_after_last) > static_cast<T>(first_index))
            {
                const std::shared_ptr<std::decay_t<F>> block_ptr = std::make_shared<std::decay_t<F>>(std::forward<F>(block));
                const Blocks blks(static_cast<T>(first_index), static_cast<T>(index_after_last), num_blocks ? num_blocks : thread_count);
                MultiFuture<R> future;
                future.reserve(blks.get_num_blocks());
                for (std::size_t blk = 0; blk < blks.get_num_blocks(); ++blk)
                {
                    future.push_back(SubmitTask(
                        [block_ptr, start = blks.start(blk), end = blks.end(blk)]
                        {
                            return (*block_ptr)(start, end);
                        },
                        priority));
                }
                return future;
            }
            return {};
        }

        // Parallelize a loop by automatically splitting it into blocks and submitting each block separately to the queue, with the specified priority. The loop function takes one argument, the loop index, so that it is called many times per block. It must have no return value. Returns a `MultiFuture` that contains the futures for all of the blocks.
        // T1 The type of the first index. Should be a signed or unsigned integer.
        // T2 The type of the index after the last index. Should be a signed or unsigned integer.
        // F The type of the function to loop through.
        // first_index The first index in the loop.
        // index_after_last The index after the last index in the loop. The loop will iterate from `first_index` to `(index_after_last - 1)` inclusive. In other words, it will be equivalent to `for (T i = first_index; i < index_after_last; ++i)`. Note that if `index_after_last <= first_index`, no tasks will be submitted, and an empty `MultiFuture` will be returned.
        // loop The function to loop through. Will be called once per index, many times per block. Should take exactly one argument: the loop index. It cannot have a return value.
        // num_blocks The maximum number of blocks to split the loop into. The default is 0, which means the number of blocks will be equal to the number of threads in the pool.
        // priority The priority of the tasks. Should be between -128 and +127 (a signed 8-bit integer). The default is 0. Only taken into account if the flag `tp::priority` is enabled in the template parameter, otherwise has no effect.
        // return A `MultiFuture` that can be used to wait for all the blocks to finish.
        template <typename T1, typename T2, typename T = common_index_type_t<T1, T2>, typename F>
        [[nodiscard]] MultiFuture<void> SubmitLoop(const T1 first_index, const T2 index_after_last, F&& loop, const std::size_t num_blocks = 0, const priority_t priority = 0)
        {
            if (static_cast<T>(index_after_last) > static_cast<T>(first_index))
            {
                const std::shared_ptr<std::decay_t<F>> loop_ptr = std::make_shared<std::decay_t<F>>(std::forward<F>(loop));
                const Blocks blks(static_cast<T>(first_index), static_cast<T>(index_after_last), num_blocks ? num_blocks : thread_count);
                MultiFuture<void> future;
                future.reserve(blks.get_num_blocks());
                for (std::size_t blk = 0; blk < blks.get_num_blocks(); ++blk)
                {
                    future.push_back(SubmitTask(
                        [loop_ptr, start = blks.start(blk), end = blks.end(blk)]
                        {
                            for (T i = start; i < end; ++i)
                                (*loop_ptr)(i);
                        },
                        priority));
                }
                return future;
            }
            return {};
        }

        // Submit a sequence of tasks enumerated by indices to the queue, with the specified priority. The sequence function takes one argument, the task index, and will be called once per index. Returns a `MultiFuture` that contains the futures for all of the tasks.
        // T1 The type of the first index. Should be a signed or unsigned integer.
        // T2 The type of the index after the last index. Should be a signed or unsigned integer.
        // F The type of the function used to define the sequence.
        // R The return type of the function used to define the sequence (can be `void`).
        // first_index The first index in the sequence.
        // index_after_last The index after the last index in the sequence. The sequence will iterate from `first_index` to `(index_after_last - 1)` inclusive. In other words, it will be equivalent to `for (T i = first_index; i < index_after_last; ++i)`. Note that if `index_after_last <= first_index`, no tasks will be submitted, and an empty `MultiFuture` will be returned.
        // sequence The function used to define the sequence. Will be called once per index. Should take exactly one argument, the index.
        // priority The priority of the tasks. Should be between -128 and +127 (a signed 8-bit integer). The default is 0. Only taken into account if the flag `tp::priority` is enabled in the template parameter, otherwise has no effect.
        // return A `MultiFuture` that can be used to wait for all the tasks to finish. If the sequence function returns a value, the `MultiFuture` can also be used to obtain the values returned by each task.
        template <typename T1, typename T2, typename T = common_index_type_t<T1, T2>, typename F, typename R = std::invoke_result_t<std::decay_t<F>, T>>
        [[nodiscard]] MultiFuture<R> SubmitSequence(const T1 first_index, const T2 index_after_last, F&& sequence, const priority_t priority = 0)
        {
            if (static_cast<T>(index_after_last) > static_cast<T>(first_index))
            {
                const std::shared_ptr<std::decay_t<F>> sequence_ptr = std::make_shared<std::decay_t<F>>(std::forward<F>(sequence));
                MultiFuture<R> future;
                future.reserve(static_cast<std::size_t>(static_cast<T>(index_after_last) > static_cast<T>(first_index)));
                for (T i = static_cast<T>(first_index); i < static_cast<T>(index_after_last); ++i)
                {
                    future.push_back(SubmitTask(
                        [sequence_ptr, i]
                        {
                            return (*sequence_ptr)(i);
                        },
                        priority));
                }
                return future;
            }
            return {};
        }

        // Submit a function with no arguments into the task queue, with the specified priority. To submit a function with arguments, enclose it in a lambda expression. If the function has a return value, get a future for the eventual returned value. If the function has no return value, get an `std::future<void>` which can be used to wait until the task finishes.
        // F The type of the function.
        // R The return type of the function (can be `void`).
        // task The function to submit.
        // priority The priority of the task. Should be between -128 and +127 (a signed 8-bit integer). The default is 0. Only taken into account if the flag `tp::priority` is enabled in the template parameter, otherwise has no effect.
        // return A future to be used later to wait for the function to finish executing and/or obtain its returned value if it has one.
        template <typename F, typename R = std::invoke_result_t<std::decay_t<F>>>
        [[nodiscard]] std::future<R> SubmitTask(F&& task, const priority_t priority = 0)
        {
#ifdef __cpp_lib_move_only_function
            std::promise<R> promise;
        #define qor_pp_thread_pool_promise_member_access promise.
#else
            const std::shared_ptr<std::promise<R>> promise = std::make_shared<std::promise<R>>();
        #define qor_pp_thread_pool_promise_member_access promise->
#endif
            std::future<R> future = qor_pp_thread_pool_promise_member_access get_future();
            PostTask(
                [task = std::forward<F>(task), promise = std::move(promise)]() mutable
                {
#ifdef __cpp_exceptions
                    try
                    {
#endif
                        if constexpr (std::is_void_v<R>)
                        {
                            task();
                            qor_pp_thread_pool_promise_member_access set_value();
                        }
                        else
                        {
                            qor_pp_thread_pool_promise_member_access set_value(task());
                        }
#ifdef __cpp_exceptions
                    }
                    catch (...)
                    {
                        try
                        {
                            qor_pp_thread_pool_promise_member_access set_exception(std::current_exception());
                        }
                        catch (...)
                        {
                        }
                    }
#endif
                },
                priority);
            return future;
        }

        // Unpause the pool. The workers will resume retrieving new tasks out of the queue. 
        void Unpause()
        {
            {
                const std::scoped_lock tasks_lock(tasks_mutex);
                paused = false;
            }
            task_available_cv.notify_all();
        }

        // Wait for tasks to be completed. Normally, this function waits for all tasks, both those that are currently running in the threads and those that are still waiting in the queue. However, if the pool is paused, this function only waits for the currently running tasks (otherwise it would wait forever). Note: To wait for just one specific task, use `SubmitTask()` instead, and call the `wait()` member function of the generated future.
        // throws `wait_deadlock` if called from within a thread of the same pool, which would result in a deadlock. Only enabled if the flag `BS:tp::wait_deadlock_checks` is enabled in the template parameter.
        void Wait()
        {
#ifdef __cpp_exceptions
            if (wait_deadlock_checks_enabled)
            {
                if (CurrentThread::GetCurrent().GetPool() == this)
                    throw wait_deadlock();
            }
#endif
            std::unique_lock tasks_lock(tasks_mutex);
            waiting = true;
            tasks_done_cv.wait(tasks_lock,
                [this]
                {
                    return (tasks_running == 0) && (paused || tasks.empty());
                });
            waiting = false;
        }

        // Wait for tasks to be completed, but stop waiting after the specified duration has passed.
        // R An arithmetic type representing the number of ticks to wait.
        // P An `std::ratio` representing the length of each tick in seconds.
        // duration The amount of time to wait.
        // return `true` if all tasks finished running, `false` if the duration expired but some tasks are still running.
        // throws `wait_deadlock` if called from within a thread of the same pool, which would result in a deadlock. Only enabled if the flag `BS:tp::wait_deadlock_checks` is enabled in the template parameter.
        template <typename R, typename P>
        bool WaitFor(const std::chrono::duration<R, P>& duration)
        {
#ifdef __cpp_exceptions
            if (wait_deadlock_checks_enabled)
            {
                if (CurrentThread::GetCurrent().GetPool() == this)
                    throw wait_deadlock();
            }
#endif
            std::unique_lock tasks_lock(tasks_mutex);
            waiting = true;
            const bool status = tasks_done_cv.wait_for(tasks_lock, duration,
                [this]
                {
                    return (tasks_running == 0) && (paused || tasks.empty());
                });
            waiting = false;
            return status;
        }

        //Wait for tasks to be completed, but stop waiting after the specified time point has been reached.
        // C The type of the clock used to measure time.
        // D An `std::chrono::duration` type used to indicate the time point.
        // timeout_time The time point at which to stop waiting.
        // return `true` if all tasks finished running, `false` if the time point was reached but some tasks are still running.
        // throws `wait_deadlock` if called from within a thread of the same pool, which would result in a deadlock. 
        template <typename C, typename D>
        bool WaitUntil(const std::chrono::time_point<C, D>& timeout_time)
        {
#ifdef __cpp_exceptions
            if (wait_deadlock_checks_enabled)
            {
                if (CurrentThread::GetCurrent().GetPool() == this)
                {
                    throw wait_deadlock();
                }
            }
#endif
            std::unique_lock tasks_lock(tasks_mutex);
            waiting = true;
            const bool status = tasks_done_cv.wait_until(tasks_lock, timeout_time,
                [this]
                {
                    return (tasks_running == 0) && (paused || tasks.empty());
                });
            waiting = false;
            return status;
        }

        auto Schedule() 
        {
            struct Awaiter : std::suspend_always 
            {
                ThreadPool &tpool;
                Awaiter(ThreadPool &pool) : tpool{pool} {}
                void await_suspend(std::coroutine_handle<> handle) 
                {
                    tpool.PostTask([handle, this]() { handle.resume(); });
                }
            };
            return Awaiter{*this};
        }  

    private:
            
        template <typename F>
        void SetInitFunction(F&& init)
        {
            if constexpr (std::is_invocable_v<F, std::size_t>)
            {
                init_func = std::forward<F>(init);
            }
            else
            {
                init_func = [init = std::forward<F>(init)](std::size_t)
                {
                    init();
                };
            }
        }
        void SetThreadCount(const std::size_t num_threads);
        void CreateThreads();
        static std::size_t DetermineThreadCount(const std::size_t num_threads) noexcept;
        task_t PopTask();

        template <typename F>
        void ResetPool(const std::size_t num_threads, F&& init)                                         //Reset the pool with a new number of threads and a new initialization function. This member function implements the actual reset, while the public member function `reset()` also handles the case where the pool is paused.
        {
            Wait();
            SetInitFunction(std::forward<F>(init));
            SetThreadCount(num_threads);
            CreateThreads();
        }
        
        void Worker(const std::stop_token &stop_token, const std::size_t idx);                          //A worker function to be assigned to each thread in the pool. Waits until it is notified by `PostTask()` that a task is available, and then retrieves the task from the queue and executes it. Once the task finishes, the worker notifies `wait()` in case it is waiting.
        ThreadPool(const ThreadPool&) = delete;                                                         // The copy and move constructors and assignment operators are deleted. The thread pool cannot be copied or moved.
        ThreadPool(ThreadPool&&) = delete;
        ThreadPool& operator=(const ThreadPool&) = delete;
        ThreadPool& operator=(ThreadPool&&) = delete;

        function_t<void(std::size_t)> cleanup_func = [](std::size_t) {};        //A cleanup function to run in each thread right before it is destroyed, which will happen when the pool is destructed or reset. The function must have no return value, and can either take one argument, the thread index of type `std::size_t`, or zero arguments. The cleanup function must not throw any exceptions, as that will result in program termination. Any exceptions must be handled explicitly within the function. The default is an empty function, i.e., no cleanup will be performed.
        function_t<void(std::size_t)> init_func = [](std::size_t) {};           //An initialization function to run in each thread before it starts executing any submitted tasks. The function must have no return value, and can either take one argument, the thread index of type `std::size_t`, or zero arguments. It will be executed exactly once per thread, when the thread is first constructed. The initialization function must not throw any exceptions, as that will result in program termination. Any exceptions must be handled explicitly within the function. The default is an empty function, i.e., no initialization will be performed.
        bool paused = false;                                                    //A flag indicating whether the workers should pause. When set to `true`, the workers temporarily stop retrieving new tasks out of the queue, although any tasks already executed will keep running until they are finished. When set to `false` again, the workers resume retrieving tasks. Only enabled if the flag `BS:tp::pause` is enabled in the template parameter.
        std::condition_variable_any task_available_cv;                          //A condition variable to notify `Worker()` that a new task has become available.
        std::condition_variable tasks_done_cv;                                  //A condition variable to notify `wait()` that the tasks are done.
        std::priority_queue<pr_task> tasks;                                     //A priority queue of tasks to be executed by the threads.
        mutable std::mutex tasks_mutex;                                         // mutex to synchronize access to the task queue by different threads.
        std::size_t tasks_running = 0;                                          //A counter for the total number of currently running tasks.
        std::size_t thread_count = 0;                                           //The number of threads in the pool.
        std::unique_ptr<thread_t[]> threads = nullptr;                          //A smart pointer to manage the memory allocated for the threads.
        bool waiting = false;                                                   //A flag indicating that `wait()` is active and expects to be notified whenever a task is done.
    }; 

    using binary_semaphore = std::binary_semaphore;
    template <std::ptrdiff_t LeastMaxValue = std::counting_semaphore<>::max()>
    using counting_semaphore = std::counting_semaphore<LeastMaxValue>;

    }//qor::framework

}//qor

#endif // QOR_PP_H_FRAMEWORK_THREADPOOL
