// Copyright Querysoft Limited 2008 - 2025
//
// Permission is hereby granted, free of charge, to any person or organization
// obtaining a copy of the software and accompanying documentation covered by
// this license (the "Software") to use, reproduce, display, distribute,
// execute, and transmit the Software, and to prepare derivative works of the
// Software, and to permit third-parties to whom the Software is furnished to
// do so, all subject to the following:
// 
// The copyright notices in the Software and this entire statement, including
// the above license grant, this restriction and the following disclaimer,
// must be included in all copies of the Software, in whole or in part, and
// all derivative works of the Software, unless such copies or derivative
// works are solely in the form of machine-executable object code generated by
// a source language processor.
// 
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
// SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
// FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
// DEALINGS IN THE SOFTWARE.

#ifndef QOR_PP_H_FRAMEWORK_THREADPOOL
#define QOR_PP_H_FRAMEWORK_THREADPOOL
 
#include <algorithm>
#include <chrono>
#include <condition_variable>
#include <coroutine>
#include <cstddef>
#include <cstdint>
#include <functional>
#include <future>
#include <iostream>
#include <limits>
#include <memory>
#include <mutex>
#include <optional>
#include <queue>
#include <string>
#include <thread>
#include <tuple>
#include <type_traits>
#include <utility>
#include <variant>
#include <vector>
#ifdef __cpp_concepts
    #include <concepts>
#endif
#ifdef __cpp_exceptions
    #include <exception>
    #include <stdexcept>
#endif
#ifdef __cpp_impl_three_way_comparison
    #include <compare>
#endif
#ifdef __cpp_lib_int_pow2
    #include <bit>
#endif
#ifdef __cpp_lib_semaphore
    #include <semaphore>
#endif
#include <stop_token>
#include "pool/version.h"
#include "pool/types.h"
#include "pool/pr_task.h"
#include "pool/concepts.h"
#include "pool/multi_future.h"
#include "pool/blocks.h"
#include "pool/native_extensions.h"
#include "currentthread.h"
#include "pool/common_index_type.h"

namespace qor { namespace framework{

    //An enumeration of flags to be used in the bitmask template parameter of `qor::thread_pool` to enable optional features.
    enum tp : opt_t
    {
        none = 0,                      //No optional features enabled.
        priority = 1 << 0,             //Enable task priority.
        pause = 1 << 2,                //Enable pausing.
        wait_deadlock_checks = 1 << 3  //Enable wait deadlock checks.
    };
    
#ifdef __cpp_exceptions
    //An exception that will be thrown by `wait()`, `wait_for()`, and `wait_until()` if the user tries to call them from within a thread of the same pool, which would result in a deadlock. Only used if the flag `tp::wait_deadlock_checks` is enabled in the template parameter of `thread_pool`.
    struct wait_deadlock : public std::runtime_error
    {
        wait_deadlock() : std::runtime_error("wait_deadlock") {};
    };
#endif

    template <opt_t OptFlags = tp::none>
    class [[nodiscard]] thread_pool
    {
    public:
        
        static constexpr bool priority_enabled = (OptFlags & tp::priority) != 0;       //A flag indicating whether task priority is enabled.
        static constexpr bool pause_enabled = (OptFlags & tp::pause) != 0;     //A flag indicating whether pausing is enabled.
        static constexpr bool wait_deadlock_checks_enabled = (OptFlags & tp::wait_deadlock_checks) != 0;       //A flag indicating whether wait deadlock checks are enabled.

#ifndef __cpp_exceptions
        static_assert(!wait_deadlock_checks_enabled, "Wait deadlock checks cannot be enabled if exception handling is disabled.");
#endif

        thread_pool() : thread_pool(0, [] {}) {}       //Construct a new thread pool. The number of threads will be the total number of hardware threads available, as reported by the implementation. This is usually determined by the number of cores in the CPU. If a core is hyperthreaded, it will count as two threads.
        explicit thread_pool(const std::size_t num_threads) : thread_pool(num_threads, [] {}) {}       //Construct a new thread pool with the specified number of threads.
        
        template <qor_pp_threadpool_init_func_concept(F)>      //Construct a new thread pool with the specified initialization function.
        explicit thread_pool(F&& init) : thread_pool(0, std::forward<F>(init)) {}

        template <qor_pp_threadpool_init_func_concept(F)>      // Construct a new thread pool with the specified number of threads and initialization function.
        thread_pool(const std::size_t num_threads, F&& init)
        {
            create_threads(num_threads, std::forward<F>(init));
        }

        // The copy and move constructors and assignment operators are deleted. The thread pool cannot be copied or moved.
        thread_pool(const thread_pool&) = delete;
        thread_pool(thread_pool&&) = delete;
        thread_pool& operator=(const thread_pool&) = delete;
        thread_pool& operator=(thread_pool&&) = delete;

        //Destruct the thread pool. Waits for all tasks to complete, then destroys all threads. If a cleanup function was set, it will run in each thread right before it is destroyed. Note that if the pool is paused, then any tasks still in the queue will never be executed.
        ~thread_pool() noexcept
        {
#ifdef __cpp_exceptions
            try
            {
#endif
                wait();
#ifdef __cpp_exceptions
            }
            catch (...)
            {
            }
#endif
        }

        //Parallelize a loop by automatically splitting it into blocks and submitting each block separately to the queue, with the specified priority. The block function takes two arguments, the start and end of the block, so that it is only called once per block, but it is up to the user make sure the block function correctly deals with all the indices in each block. Does not return a `multi_future`, so the user must use `wait()` or some other method to ensure that the loop finishes executing, otherwise bad things will happen.
        //T1 The type of the first index. Should be a signed or unsigned integer.
        //T2 The type of the index after the last index. Should be a signed or unsigned integer.
        //F The type of the function to loop through.
        //first_index The first index in the loop.
        //index_after_last The index after the last index in the loop. The loop will iterate from `first_index` to `(index_after_last - 1)` inclusive. In other words, it will be equivalent to `for (T i = first_index; i < index_after_last; ++i)`. Note that if `index_after_last <= first_index`, no blocks will be submitted.
        //block A function that will be called once per block. Should take exactly two arguments: the first index in the block and the index after the last index in the block. `block(start, end)` should typically involve a loop of the form `for (T i = start; i < end; ++i)`.
        //num_blocks The maximum number of blocks to split the loop into. The default is 0, which means the number of blocks will be equal to the number of threads in the pool.
        //priority The priority of the tasks. Should be between -128 and +127 (a signed 8-bit integer). The default is 0. Only taken into account if the flag `BS:tp::priority` is enabled in the template parameter, otherwise has no effect.
        template <typename T1, typename T2, typename T = common_index_type_t<T1, T2>, typename F>
        void detach_blocks(const T1 first_index, const T2 index_after_last, F&& block, const std::size_t num_blocks = 0, const priority_t priority = 0)
        {
            if (static_cast<T>(index_after_last) > static_cast<T>(first_index))
            {
                const std::shared_ptr<std::decay_t<F>> block_ptr = std::make_shared<std::decay_t<F>>(std::forward<F>(block));
                const blocks blks(static_cast<T>(first_index), static_cast<T>(index_after_last), num_blocks ? num_blocks : thread_count);
                for (std::size_t blk = 0; blk < blks.get_num_blocks(); ++blk)
                {
                    detach_task(
                        [block_ptr, start = blks.start(blk), end = blks.end(blk)]
                        {
                            (*block_ptr)(start, end);
                        },
                        priority);
                }
            }
        }

        // Parallelize a loop by automatically splitting it into blocks and submitting each block separately to the queue, with the specified priority. The loop function takes one argument, the loop index, so that it is called many times per block. Does not return a `multi_future`, so the user must use `wait()` or some other method to ensure that the loop finishes executing, otherwise bad things will happen.
        // T1 The type of the first index. Should be a signed or unsigned integer.
        // T2 The type of the index after the last index. Should be a signed or unsigned integer.
        // F The type of the function to loop through.
        // first_index The first index in the loop.
        // index_after_last The index after the last index in the loop. The loop will iterate from `first_index` to `(index_after_last - 1)` inclusive. In other words, it will be equivalent to `for (T i = first_index; i < index_after_last; ++i)`. Note that if `index_after_last <= first_index`, no blocks will be submitted.
        // loop The function to loop through. Will be called once per index, many times per block. Should take exactly one argument: the loop index.
        // num_blocks The maximum number of blocks to split the loop into. The default is 0, which means the number of blocks will be equal to the number of threads in the pool.
        // priority The priority of the tasks. Should be between -128 and +127 (a signed 8-bit integer). The default is 0. Only taken into account if the flag `BS:tp::priority` is enabled in the template parameter, otherwise has no effect.
        template <typename T1, typename T2, typename T = common_index_type_t<T1, T2>, typename F>
        void detach_loop(const T1 first_index, const T2 index_after_last, F&& loop, const std::size_t num_blocks = 0, const priority_t priority = 0)
        {
            if (static_cast<T>(index_after_last) > static_cast<T>(first_index))
            {
                const std::shared_ptr<std::decay_t<F>> loop_ptr = std::make_shared<std::decay_t<F>>(std::forward<F>(loop));
                const blocks blks(static_cast<T>(first_index), static_cast<T>(index_after_last), num_blocks ? num_blocks : thread_count);
                for (std::size_t blk = 0; blk < blks.get_num_blocks(); ++blk)
                {
                    detach_task(
                        [loop_ptr, start = blks.start(blk), end = blks.end(blk)]
                        {
                            for (T i = start; i < end; ++i)
                                (*loop_ptr)(i);
                        },
                        priority);
                }
            }
        }

        //Submit a sequence of tasks enumerated by indices to the queue, with the specified priority. The sequence function takes one argument, the task index, and will be called once per index. Does not return a `multi_future`, so the user must use `wait()` or some other method to ensure that the sequence finishes executing, otherwise bad things will happen.
        // T1 The type of the first index. Should be a signed or unsigned integer.
        // T2 The type of the index after the last index. Should be a signed or unsigned integer.
        // F The type of the function used to define the sequence.
        // first_index The first index in the sequence.
        // index_after_last The index after the last index in the sequence. The sequence will iterate from `first_index` to `(index_after_last - 1)` inclusive. In other words, it will be equivalent to `for (T i = first_index; i < index_after_last; ++i)`. Note that if `index_after_last <= first_index`, no tasks will be submitted.
        // sequence The function used to define the sequence. Will be called once per index. Should take exactly one argument, the index.
        // priority The priority of the tasks. Should be between -128 and +127 (a signed 8-bit integer). The default is 0. Only taken into account if the flag `BS:tp::priority` is enabled in the template parameter, otherwise has no effect.
        template <typename T1, typename T2, typename T = common_index_type_t<T1, T2>, typename F>
        void detach_sequence(const T1 first_index, const T2 index_after_last, F&& sequence, const priority_t priority = 0)
        {
            if (static_cast<T>(index_after_last) > static_cast<T>(first_index))
            {
                const std::shared_ptr<std::decay_t<F>> sequence_ptr = std::make_shared<std::decay_t<F>>(std::forward<F>(sequence));
                for (T i = static_cast<T>(first_index); i < static_cast<T>(index_after_last); ++i)
                {
                    detach_task(
                        [sequence_ptr, i]
                        {
                            (*sequence_ptr)(i);
                        },
                        priority);
                }
            }
        }

        //Submit a function with no arguments and no return value into the task queue, with the specified priority. To submit a function with arguments, enclose it in a lambda expression. Does not return a future, so the user must use `wait()` or some other method to ensure that the task finishes executing, otherwise bad things will happen.
        // F The type of the function.
        // task The function to submit.
        // priority The priority of the task. Should be between -128 and +127 (a signed 8-bit integer). The default is 0. Only taken into account if the flag `BS:tp::priority` is enabled in the template parameter, otherwise has no effect.
        template <typename F>
        void detach_task(F&& task, const priority_t priority = 0)
        {
            {
                const std::scoped_lock tasks_lock(tasks_mutex);
                if constexpr (priority_enabled)
                    tasks.emplace(std::forward<F>(task), priority);
                else
                    tasks.emplace(std::forward<F>(task));
            }
            task_available_cv.notify_one();
        }

        //Get a vector containing the underlying implementation-defined thread handles for each of the pool's threads, as obtained by `std::thread::native_handle()` (or `std::jthread::native_handle()` in C++20 and later).
        //return The native thread handles.     
        [[nodiscard]] std::vector<thread_t::native_handle_type> get_native_handles() const
        {
            std::vector<thread_t::native_handle_type> native_handles(thread_count);
            for (std::size_t i = 0; i < thread_count; ++i)
                native_handles[i] = threads[i].native_handle();
            return native_handles;
        }

        //Get the number of tasks currently waiting in the queue to be executed by the threads.
        [[nodiscard]] std::size_t get_tasks_queued() const
        {
            const std::scoped_lock tasks_lock(tasks_mutex);
            return tasks.size();
        }

        //Get the number of tasks currently being executed by the threads.
        [[nodiscard]] std::size_t get_tasks_running() const
        {
            const std::scoped_lock tasks_lock(tasks_mutex);
            return tasks_running;
        }

        //Get the total number of unfinished tasks: either still waiting in the queue, or running in a thread. Note that `get_tasks_total() == get_tasks_queued() + get_tasks_running()`.
        //return The total number of tasks.
        [[nodiscard]] std::size_t get_tasks_total() const
        {
            const std::scoped_lock tasks_lock(tasks_mutex);
            return tasks_running + tasks.size();
        }

        [[nodiscard]] std::size_t get_thread_count() const noexcept
        {
            return thread_count;
        }

        //Get a vector containing the unique identifiers for each of the pool's threads, as obtained by `std::thread::get_id()` (or `std::jthread::get_id()` in C++20 and later).
        //return The unique thread identifiers.
        [[nodiscard]] std::vector<thread_t::id> get_thread_ids() const
        {
            std::vector<thread_t::id> thread_ids(thread_count);
            for (std::size_t i = 0; i < thread_count; ++i)
                thread_ids[i] = threads[i].get_id();
            return thread_ids;
        }

        //Check whether the pool is currently paused. Only enabled if the flag `BS:tp::pause` is enabled in the template parameter.
        //return `true` if the pool is paused, `false` if it is not paused.
        qor_pp_threadpool_if_pause_enabled
        [[nodiscard]] bool is_paused() const
        {
            const std::scoped_lock tasks_lock(tasks_mutex);
            return paused;
        }

        //Pause the pool. The workers will temporarily stop retrieving new tasks out of the queue, although any tasks already executed will keep running until they are finished. Only enabled if the flag `BS:tp::pause` is enabled in the template parameter.
        qor_pp_threadpool_if_pause_enabled
        void pause()
        {
            const std::scoped_lock tasks_lock(tasks_mutex);
            paused = true;
        }

        // Purge all the tasks waiting in the queue. Tasks that are currently running will not be affected, but any tasks still waiting in the queue will be discarded, and will never be executed by the threads. Please note that there is no way to restore the purged tasks.
        void purge()
        {
            const std::scoped_lock tasks_lock(tasks_mutex);
            tasks = {};
        }

        //Reset the pool with the total number of hardware threads available, as reported by the implementation. Waits for all currently running tasks to be completed, then destroys all threads in the pool and creates a new thread pool with the new number of threads. Any tasks that were waiting in the queue before the pool was reset will then be executed by the new threads. If the pool was paused before resetting it, the new pool will be paused as well.
        void reset()
        {
            reset(0, [](std::size_t) {});
        }

        //Reset the pool with a new number of threads. Waits for all currently running tasks to be completed, then destroys all threads in the pool and creates a new thread pool with the new number of threads. Any tasks that were waiting in the queue before the pool was reset will then be executed by the new threads. If the pool was paused before resetting it, the new pool will be paused as well.
        // num_threads The number of threads to use.
        void reset(const std::size_t num_threads)
        {
            reset(num_threads, [](std::size_t) {});
        }

        //Reset the pool with the total number of hardware threads available, as reported by the implementation, and a new initialization function. Waits for all currently running tasks to be completed, then destroys all threads in the pool and creates a new thread pool with the new number of threads and initialization function. Any tasks that were waiting in the queue before the pool was reset will then be executed by the new threads. If the pool was paused before resetting it, the new pool will be paused as well.
        // init An initialization function to run in each thread before it starts executing any submitted tasks. The function must have no return value, and can either take one argument, the thread index of type `std::size_t`, or zero arguments. It will be executed exactly once per thread, when the thread is first constructed. The initialization function must not throw any exceptions, as that will result in program termination. Any exceptions must be handled explicitly within the function.
        template <qor_pp_threadpool_init_func_concept(F)>
        void reset(F&& init)
        {
            reset(0, std::forward<F>(init));
        }

        // Reset the pool with a new number of threads and a new initialization function. Waits for all currently running tasks to be completed, then destroys all threads in the pool and creates a new thread pool with the new number of threads and initialization function. Any tasks that were waiting in the queue before the pool was reset will then be executed by the new threads. If the pool was paused before resetting it, the new pool will be paused as well.
        // num_threads The number of threads to use.
        // init An initialization function to run in each thread before it starts executing any submitted tasks. The function must have no return value, and can either take one argument, the thread index of type `std::size_t`, or zero arguments. It will be executed exactly once per thread, when the thread is first constructed. The initialization function must not throw any exceptions, as that will result in program termination. Any exceptions must be handled explicitly within the function.
        template <qor_pp_threadpool_init_func_concept(F)>
        void reset(const std::size_t num_threads, F&& init)
        {
            if constexpr (pause_enabled)
            {
                std::unique_lock tasks_lock(tasks_mutex);
                const bool was_paused = paused;
                paused = true;
                tasks_lock.unlock();
                reset_pool(num_threads, std::forward<F>(init));
                tasks_lock.lock();
                paused = was_paused;
            }
            else
            {
                reset_pool(num_threads, std::forward<F>(init));
            }
        }

        // Set the thread pool's cleanup function.
        // cleanup A cleanup function to run in each thread right before it is destroyed, which will happen when the pool is destructed or reset. The function must have no return value, and can either take one argument, the thread index of type `std::size_t`, or zero arguments. The cleanup function must not throw any exceptions, as that will result in program termination. Any exceptions must be handled explicitly within the function.
        template <qor_pp_threadpool_init_func_concept(F)>
        void set_cleanup_func(F&& cleanup)
        {
            if constexpr (std::is_invocable_v<F, std::size_t>)
            {
                cleanup_func = std::forward<F>(cleanup);
            }
            else
            {
                cleanup_func = [cleanup = std::forward<F>(cleanup)](std::size_t)
                {
                    cleanup();
                };
            }
        }

        // Parallelize a loop by automatically splitting it into blocks and submitting each block separately to the queue, with the specified priority. The block function takes two arguments, the start and end of the block, so that it is only called once per block, but it is up to the user make sure the block function correctly deals with all the indices in each block. Returns a `multi_future` that contains the futures for all of the blocks.
        // T1 The type of the first index. Should be a signed or unsigned integer.
        // T2 The type of the index after the last index. Should be a signed or unsigned integer.
        // F The type of the function to loop through.
        // R The return type of the function to loop through (can be `void`).
        // first_index The first index in the loop.
        // index_after_last The index after the last index in the loop. The loop will iterate from `first_index` to `(index_after_last - 1)` inclusive. In other words, it will be equivalent to `for (T i = first_index; i < index_after_last; ++i)`. Note that if `index_after_last <= first_index`, no blocks will be submitted, and an empty `multi_future` will be returned.
        // block A function that will be called once per block. Should take exactly two arguments: the first index in the block and the index after the last index in the block. `block(start, end)` should typically involve a loop of the form `for (T i = start; i < end; ++i)`.
        // num_blocks The maximum number of blocks to split the loop into. The default is 0, which means the number of blocks will be equal to the number of threads in the pool.
        // priority The priority of the tasks. Should be between -128 and +127 (a signed 8-bit integer). The default is 0. Only taken into account if the flag `BS:tp::priority` is enabled in the template parameter, otherwise has no effect.
        // A `multi_future` that can be used to wait for all the blocks to finish. If the block function returns a value, the `multi_future` can also be used to obtain the values returned by each block.
        template <typename T1, typename T2, typename T = common_index_type_t<T1, T2>, typename F, typename R = std::invoke_result_t<std::decay_t<F>, T, T>>
        [[nodiscard]] multi_future<R> submit_blocks(const T1 first_index, const T2 index_after_last, F&& block, const std::size_t num_blocks = 0, const priority_t priority = 0)
        {
            if (static_cast<T>(index_after_last) > static_cast<T>(first_index))
            {
                const std::shared_ptr<std::decay_t<F>> block_ptr = std::make_shared<std::decay_t<F>>(std::forward<F>(block));
                const blocks blks(static_cast<T>(first_index), static_cast<T>(index_after_last), num_blocks ? num_blocks : thread_count);
                multi_future<R> future;
                future.reserve(blks.get_num_blocks());
                for (std::size_t blk = 0; blk < blks.get_num_blocks(); ++blk)
                {
                    future.push_back(submit_task(
                        [block_ptr, start = blks.start(blk), end = blks.end(blk)]
                        {
                            return (*block_ptr)(start, end);
                        },
                        priority));
                }
                return future;
            }
            return {};
        }

        // Parallelize a loop by automatically splitting it into blocks and submitting each block separately to the queue, with the specified priority. The loop function takes one argument, the loop index, so that it is called many times per block. It must have no return value. Returns a `multi_future` that contains the futures for all of the blocks.
        // T1 The type of the first index. Should be a signed or unsigned integer.
        // T2 The type of the index after the last index. Should be a signed or unsigned integer.
        // F The type of the function to loop through.
        // first_index The first index in the loop.
        // index_after_last The index after the last index in the loop. The loop will iterate from `first_index` to `(index_after_last - 1)` inclusive. In other words, it will be equivalent to `for (T i = first_index; i < index_after_last; ++i)`. Note that if `index_after_last <= first_index`, no tasks will be submitted, and an empty `multi_future` will be returned.
        // loop The function to loop through. Will be called once per index, many times per block. Should take exactly one argument: the loop index. It cannot have a return value.
        // num_blocks The maximum number of blocks to split the loop into. The default is 0, which means the number of blocks will be equal to the number of threads in the pool.
        // priority The priority of the tasks. Should be between -128 and +127 (a signed 8-bit integer). The default is 0. Only taken into account if the flag `BS:tp::priority` is enabled in the template parameter, otherwise has no effect.
        // return A `multi_future` that can be used to wait for all the blocks to finish.
        template <typename T1, typename T2, typename T = common_index_type_t<T1, T2>, typename F>
        [[nodiscard]] multi_future<void> submit_loop(const T1 first_index, const T2 index_after_last, F&& loop, const std::size_t num_blocks = 0, const priority_t priority = 0)
        {
            if (static_cast<T>(index_after_last) > static_cast<T>(first_index))
            {
                const std::shared_ptr<std::decay_t<F>> loop_ptr = std::make_shared<std::decay_t<F>>(std::forward<F>(loop));
                const blocks blks(static_cast<T>(first_index), static_cast<T>(index_after_last), num_blocks ? num_blocks : thread_count);
                multi_future<void> future;
                future.reserve(blks.get_num_blocks());
                for (std::size_t blk = 0; blk < blks.get_num_blocks(); ++blk)
                {
                    future.push_back(submit_task(
                        [loop_ptr, start = blks.start(blk), end = blks.end(blk)]
                        {
                            for (T i = start; i < end; ++i)
                                (*loop_ptr)(i);
                        },
                        priority));
                }
                return future;
            }
            return {};
        }

        // Submit a sequence of tasks enumerated by indices to the queue, with the specified priority. The sequence function takes one argument, the task index, and will be called once per index. Returns a `multi_future` that contains the futures for all of the tasks.
        // T1 The type of the first index. Should be a signed or unsigned integer.
        // T2 The type of the index after the last index. Should be a signed or unsigned integer.
        // F The type of the function used to define the sequence.
        // R The return type of the function used to define the sequence (can be `void`).
        // first_index The first index in the sequence.
        // index_after_last The index after the last index in the sequence. The sequence will iterate from `first_index` to `(index_after_last - 1)` inclusive. In other words, it will be equivalent to `for (T i = first_index; i < index_after_last; ++i)`. Note that if `index_after_last <= first_index`, no tasks will be submitted, and an empty `multi_future` will be returned.
        // sequence The function used to define the sequence. Will be called once per index. Should take exactly one argument, the index.
        // priority The priority of the tasks. Should be between -128 and +127 (a signed 8-bit integer). The default is 0. Only taken into account if the flag `BS:tp::priority` is enabled in the template parameter, otherwise has no effect.
        // return A `multi_future` that can be used to wait for all the tasks to finish. If the sequence function returns a value, the `multi_future` can also be used to obtain the values returned by each task.
        template <typename T1, typename T2, typename T = common_index_type_t<T1, T2>, typename F, typename R = std::invoke_result_t<std::decay_t<F>, T>>
        [[nodiscard]] multi_future<R> submit_sequence(const T1 first_index, const T2 index_after_last, F&& sequence, const priority_t priority = 0)
        {
            if (static_cast<T>(index_after_last) > static_cast<T>(first_index))
            {
                const std::shared_ptr<std::decay_t<F>> sequence_ptr = std::make_shared<std::decay_t<F>>(std::forward<F>(sequence));
                multi_future<R> future;
                future.reserve(static_cast<std::size_t>(static_cast<T>(index_after_last) > static_cast<T>(first_index)));
                for (T i = static_cast<T>(first_index); i < static_cast<T>(index_after_last); ++i)
                {
                    future.push_back(submit_task(
                        [sequence_ptr, i]
                        {
                            return (*sequence_ptr)(i);
                        },
                        priority));
                }
                return future;
            }
            return {};
        }

        // Submit a function with no arguments into the task queue, with the specified priority. To submit a function with arguments, enclose it in a lambda expression. If the function has a return value, get a future for the eventual returned value. If the function has no return value, get an `std::future<void>` which can be used to wait until the task finishes.
        // F The type of the function.
        // R The return type of the function (can be `void`).
        // task The function to submit.
        // priority The priority of the task. Should be between -128 and +127 (a signed 8-bit integer). The default is 0. Only taken into account if the flag `BS:tp::priority` is enabled in the template parameter, otherwise has no effect.
        // return A future to be used later to wait for the function to finish executing and/or obtain its returned value if it has one.
        template <typename F, typename R = std::invoke_result_t<std::decay_t<F>>>
        [[nodiscard]] std::future<R> submit_task(F&& task, const priority_t priority = 0)
        {
    #ifdef __cpp_lib_move_only_function
            std::promise<R> promise;
        #define BS_THREAD_POOL_PROMISE_MEMBER_ACCESS promise.
    #else
            const std::shared_ptr<std::promise<R>> promise = std::make_shared<std::promise<R>>();
        #define BS_THREAD_POOL_PROMISE_MEMBER_ACCESS promise->
    #endif
            std::future<R> future = BS_THREAD_POOL_PROMISE_MEMBER_ACCESS get_future();
            detach_task(
                [task = std::forward<F>(task), promise = std::move(promise)]() mutable
                {
    #ifdef __cpp_exceptions
                    try
                    {
    #endif
                        if constexpr (std::is_void_v<R>)
                        {
                            task();
                            BS_THREAD_POOL_PROMISE_MEMBER_ACCESS set_value();
                        }
                        else
                        {
                            BS_THREAD_POOL_PROMISE_MEMBER_ACCESS set_value(task());
                        }
    #ifdef __cpp_exceptions
                    }
                    catch (...)
                    {
                        try
                        {
                            BS_THREAD_POOL_PROMISE_MEMBER_ACCESS set_exception(std::current_exception());
                        }
                        catch (...)
                        {
                        }
                    }
    #endif
                },
                priority);
            return future;
        }

        // Unpause the pool. The workers will resume retrieving new tasks out of the queue. Only enabled if the flag `BS:tp::pause` is enabled in the template parameter.
        qor_pp_threadpool_if_pause_enabled
        void unpause()
        {
            {
                const std::scoped_lock tasks_lock(tasks_mutex);
                paused = false;
            }
            task_available_cv.notify_all();
        }

        // Wait for tasks to be completed. Normally, this function waits for all tasks, both those that are currently running in the threads and those that are still waiting in the queue. However, if the pool is paused, this function only waits for the currently running tasks (otherwise it would wait forever). Note: To wait for just one specific task, use `submit_task()` instead, and call the `wait()` member function of the generated future.
        // throws `wait_deadlock` if called from within a thread of the same pool, which would result in a deadlock. Only enabled if the flag `BS:tp::wait_deadlock_checks` is enabled in the template parameter.
        void wait()
        {
    #ifdef __cpp_exceptions
            if constexpr (wait_deadlock_checks_enabled)
            {
                if (CurrentThread::GetCurrent().GetPool() == this)
                    throw wait_deadlock();
            }
    #endif
            std::unique_lock tasks_lock(tasks_mutex);
            waiting = true;
            tasks_done_cv.wait(tasks_lock,
                [this]
                {
                    if constexpr (pause_enabled)
                        return (tasks_running == 0) && (paused || tasks.empty());
                    else
                        return (tasks_running == 0) && tasks.empty();
                });
            waiting = false;
        }

        // Wait for tasks to be completed, but stop waiting after the specified duration has passed.
        // R An arithmetic type representing the number of ticks to wait.
        // P An `std::ratio` representing the length of each tick in seconds.
        // duration The amount of time to wait.
        // return `true` if all tasks finished running, `false` if the duration expired but some tasks are still running.
        // throws `wait_deadlock` if called from within a thread of the same pool, which would result in a deadlock. Only enabled if the flag `BS:tp::wait_deadlock_checks` is enabled in the template parameter.
        template <typename R, typename P>
        bool wait_for(const std::chrono::duration<R, P>& duration)
        {
    #ifdef __cpp_exceptions
            if constexpr (wait_deadlock_checks_enabled)
            {
                if (CurrentThread::GetCurrent().GetPool() == this)
                    throw wait_deadlock();
            }
    #endif
            std::unique_lock tasks_lock(tasks_mutex);
            waiting = true;
            const bool status = tasks_done_cv.wait_for(tasks_lock, duration,
                [this]
                {
                    if constexpr (pause_enabled)
                        return (tasks_running == 0) && (paused || tasks.empty());
                    else
                        return (tasks_running == 0) && tasks.empty();
                });
            waiting = false;
            return status;
        }

        //Wait for tasks to be completed, but stop waiting after the specified time point has been reached.
        // C The type of the clock used to measure time.
        // D An `std::chrono::duration` type used to indicate the time point.
        // timeout_time The time point at which to stop waiting.
        // return `true` if all tasks finished running, `false` if the time point was reached but some tasks are still running.
        // throws `wait_deadlock` if called from within a thread of the same pool, which would result in a deadlock. 
        template <typename C, typename D>
        bool wait_until(const std::chrono::time_point<C, D>& timeout_time)
        {
    #ifdef __cpp_exceptions
            if constexpr (wait_deadlock_checks_enabled)
            {
                if (CurrentThread::GetCurrent().GetPool() == this)
                {
                    throw wait_deadlock();
                }
            }
    #endif
            std::unique_lock tasks_lock(tasks_mutex);
            waiting = true;
            const bool status = tasks_done_cv.wait_until(tasks_lock, timeout_time,
                [this]
                {
                    if constexpr (pause_enabled)
                        return (tasks_running == 0) && (paused || tasks.empty());
                    else
                        return (tasks_running == 0) && tasks.empty();
                });
            waiting = false;
            return status;
        }

        auto schedule() 
        {
          struct Awaiter : std::suspend_always 
          {
              thread_pool &tpool;
              Awaiter(thread_pool &pool) : tpool{pool} {}
              void await_suspend(std::coroutine_handle<> handle) 
              {
                  tpool.detach_task([handle, this]() { handle.resume(); });
              }
          };
          return Awaiter{*this};
        }  

    private:
            
        template <typename F>
        void create_threads(const std::size_t num_threads, F&& init)
        {
            if constexpr (std::is_invocable_v<F, std::size_t>)
            {
                init_func = std::forward<F>(init);
            }
            else
            {
                init_func = [init = std::forward<F>(init)](std::size_t)
                {
                    init();
                };
            }
            thread_count = determine_thread_count(num_threads);
            threads = std::make_unique<thread_t[]>(thread_count);
            {
                const std::scoped_lock tasks_lock(tasks_mutex);
                tasks_running = thread_count;
            }
            for (std::size_t i = 0; i < thread_count; ++i)
            {
                threads[i] = thread_t(
                    [this, i]
                    (const std::stop_token& stop_token)
                    {
                        worker(stop_token, i);
                    }
                );
            }
        }

        [[nodiscard]] static std::size_t determine_thread_count(const std::size_t num_threads) noexcept
        {
            if (num_threads > 0)
                return num_threads;
            if (thread_t::hardware_concurrency() > 0)
                return thread_t::hardware_concurrency();
            return 1;
        }

        [[nodiscard]] task_t pop_task()
        {
            task_t task;
            if constexpr (priority_enabled)
                task = std::move(const_cast<pr_task&>(tasks.top()).task);
            else
                task = std::move(tasks.front());
            tasks.pop();
            return task;
        }

        //Reset the pool with a new number of threads and a new initialization function. This member function implements the actual reset, while the public member function `reset()` also handles the case where the pool is paused.
        //num_threads The number of threads to use.
        //init An initialization function to run in each thread before it starts executing any submitted tasks.
        template <typename F>
        void reset_pool(const std::size_t num_threads, F&& init)
        {
            wait();
            create_threads(num_threads, std::forward<F>(init));
        }

        //A worker function to be assigned to each thread in the pool. Waits until it is notified by `detach_task()` that a task is available, and then retrieves the task from the queue and executes it. Once the task finishes, the worker notifies `wait()` in case it is waiting.
        //idx The index of this thread.
        void worker(const std::stop_token &stop_token, const std::size_t idx)
        {
            CurrentThread::GetMutableCurrent().SetPool(this);
            CurrentThread::GetMutableCurrent().SetIndex(idx);
            init_func(idx);
            while (true)
            {
                std::unique_lock tasks_lock(tasks_mutex);
                --tasks_running;
                if constexpr (pause_enabled)
                {
                    if (waiting && (tasks_running == 0) && (paused || tasks.empty()))
                        tasks_done_cv.notify_all();
                }
                else
                {
                    if (waiting && (tasks_running == 0) && tasks.empty())
                        tasks_done_cv.notify_all();
                }
                task_available_cv.wait(tasks_lock , stop_token,
                    [this]
                    {
                        if constexpr (pause_enabled)
                            return !(paused || tasks.empty());
                        else
                            return !tasks.empty();
                    });
                if (stop_token.stop_requested())
                    break;
                {
                    task_t task = pop_task(); // NOLINT(misc-const-correctness) In C++23 this cannot be const since `std::move_only_function::operator()` is not a const member function.
                    ++tasks_running;
                    tasks_lock.unlock();
    #ifdef __cpp_exceptions
                    try
                    {
    #endif
                        task();
    #ifdef __cpp_exceptions
                    }
                    catch (...)
                    {
                    }
    #endif
                }
            }
            cleanup_func(idx);
            CurrentThread::GetMutableCurrent().SetIndex(std::nullopt);
            CurrentThread::GetMutableCurrent().SetPool(std::nullopt);
        }

        function_t<void(std::size_t)> cleanup_func = [](std::size_t) {};       //A cleanup function to run in each thread right before it is destroyed, which will happen when the pool is destructed or reset. The function must have no return value, and can either take one argument, the thread index of type `std::size_t`, or zero arguments. The cleanup function must not throw any exceptions, as that will result in program termination. Any exceptions must be handled explicitly within the function. The default is an empty function, i.e., no cleanup will be performed.
        function_t<void(std::size_t)> init_func = [](std::size_t) {};      //An initialization function to run in each thread before it starts executing any submitted tasks. The function must have no return value, and can either take one argument, the thread index of type `std::size_t`, or zero arguments. It will be executed exactly once per thread, when the thread is first constructed. The initialization function must not throw any exceptions, as that will result in program termination. Any exceptions must be handled explicitly within the function. The default is an empty function, i.e., no initialization will be performed.
        std::conditional_t<pause_enabled, bool, std::monostate> paused = {};       //A flag indicating whether the workers should pause. When set to `true`, the workers temporarily stop retrieving new tasks out of the queue, although any tasks already executed will keep running until they are finished. When set to `false` again, the workers resume retrieving tasks. Only enabled if the flag `BS:tp::pause` is enabled in the template parameter.

        std::condition_variable_any task_available_cv;     //A condition variable to notify `worker()` that a new task has become available.

        std::condition_variable tasks_done_cv;     //A condition variable to notify `wait()` that the tasks are done.
        std::conditional_t<priority_enabled, std::priority_queue<pr_task>, std::queue<task_t>> tasks;      //A queue of tasks to be executed by the threads.
        mutable std::mutex tasks_mutex;        // mutex to synchronize access to the task queue by different threads.
        std::size_t tasks_running = 0;     //A counter for the total number of currently running tasks.
        std::size_t thread_count = 0;      //The number of threads in the pool.
        std::unique_ptr<thread_t[]> threads = nullptr;     //A smart pointer to manage the memory allocated for the threads.
        bool waiting = false;      //A flag indicating that `wait()` is active and expects to be notified whenever a task is done.
    }; 

#include "pool/synced_stream.h"

#ifdef __cpp_lib_semaphore
    using binary_semaphore = std::binary_semaphore;
    template <std::ptrdiff_t LeastMaxValue = std::counting_semaphore<>::max()>
    using counting_semaphore = std::counting_semaphore<LeastMaxValue>;
#else
#   include "pool/counting_semaphore.h"
#endif

}}//qor::framework

#endif // QOR_PP_H_FRAMEWORK_THREADPOOL